"""LangGraph ReAct Agent
1. ReAct å¾ªçŽ¯: Agent -> Tools -> Agent ... -> End
2. æ”¯æŒå¤šè½®æ£€ç´¢å’ŒæŽ¨ç†
3. åŠ¨æ€å¼•ç”¨æå–
4. è‡ªåŠ¨å¯¹è¯æ‘˜è¦ (é•¿æœŸè®°å¿†)
"""

import json
import logging
from typing import Literal

from langchain_core.messages import (
    HumanMessage,
    RemoveMessage,
    SystemMessage,
    ToolMessage,
)
from langchain_core.runnables import RunnableConfig
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.graph import END, START, StateGraph
from langgraph.prebuilt import ToolNode

from app.core.prompts import FORCE_STOP_PROMPT, NO_RESULTS_MESSAGE, SUMMARIZE_PROMPT, SYSTEM_PROMPT
from app.core.rag_utils import is_meaningful_message
from app.schemas.document import VectorRetrieveFilter
from app.schemas.graph_state import ChatGraphState
from app.services.vector_service import VectorService

logger = logging.getLogger(__name__)

# æœ€å¤§è¿­ä»£æ¬¡æ•°é™åˆ¶ï¼Œé˜²æ­¢ Agent æ— é™å¾ªçŽ¯ï¼ˆä»Žé…ç½®è¯»å–ï¼‰
from app.core.config import settings

MAX_ITERATIONS = settings.AGENT_MAX_ITERATIONS


# =============================================================================
# å·¥å…·å®šä¹‰
# =============================================================================


@tool
async def search_knowledge_base(query: str, config: RunnableConfig) -> str:
    """åœ¨çŸ¥è¯†åº“ä¸­æœç´¢ç›¸å…³ä¿¡æ¯ã€‚

    å½“ç”¨æˆ·çš„é—®é¢˜éœ€è¦äº‹å®žä¾æ®ã€æ–‡æ¡£æ”¯æŒæˆ–ä½ ä¸çŸ¥é“ç­”æ¡ˆæ—¶ï¼Œ**å¿…é¡»**ä½¿ç”¨æ­¤å·¥å…·ã€‚
    å¯ä»¥å¤šæ¬¡è°ƒç”¨æ­¤å·¥å…·ä»¥æŸ¥æ‰¾ä¸åŒæ–¹é¢çš„ä¿¡æ¯ã€‚

    Args:
        query: æœç´¢æŸ¥è¯¢è¯ã€‚åº”è¯¥æ˜¯é’ˆå¯¹ç‰¹å®šä¿¡æ¯çš„æ¸…æ™°é—®é¢˜ã€‚

    Returns:
        JSON æ ¼å¼çš„å­—ç¬¦ä¸²ï¼ŒåŒ…å«æœç´¢ç»“æžœåˆ—è¡¨ã€‚
        æ¯ä¸ªç»“æžœåŒ…å« 'content' (å†…å®¹æ‘˜å½•) å’Œ 'metadata' (åŒ…å« title, document_id ç­‰)ã€‚
    """
    # èŽ·å–ç«™ç‚¹ä¸Šä¸‹æ–‡å’Œæ¶ˆæ¯åŽ†å²ä»¥è®¡ç®—åç§»é‡
    site_id = config.get("configurable", {}).get("site_id")
    messages = config.get("configurable", {}).get("messages", [])

    offset = 0
    if messages:
        for msg in messages:
            if isinstance(msg, ToolMessage) and msg.name == "search_knowledge_base":
                try:
                    prev_results = json.loads(msg.content)
                    if isinstance(prev_results, list):
                        offset += len(prev_results)
                except:
                    continue

    logger.info(
        f"ðŸ”§ [Tool] search_knowledge_base: query='{query}', site_id={site_id}, offset={offset}"
    )

    try:
        search_filter = VectorRetrieveFilter(site_id=int(site_id)) if site_id else None

        # æ‰§è¡Œæ£€ç´¢
        retrieved_docs = await VectorService.retrieve(
            query=query,
            filter=search_filter,
        )

        if not retrieved_docs:
            return NO_RESULTS_MESSAGE

        # æ ¼å¼åŒ–ç»“æžœï¼Œå¢žåŠ å…¨å±€ç´¢å¼• source_index
        results = []
        for i, doc in enumerate(retrieved_docs):
            current_idx = offset + i + 1
            results.append(
                {
                    "source_index": current_idx,
                    "title": doc.document_title,
                    "content": doc.content,
                    "metadata": {
                        "document_id": doc.document_id,
                        "title": doc.document_title,
                        "score": doc.score,
                        "source_index": current_idx,  # å†—ä½™å­˜ä¸€ä»½åœ¨ metadata
                        **doc.metadata,
                    },
                }
            )

        # ä¸ºäº†è®© AI ç»å¯¹ä¸ä¼šæ•°é”™ï¼Œæˆ‘ä»¬åœ¨è¿”å›žçš„å­—ç¬¦ä¸²ä¸­æ˜¾å¼æ ‡æ³¨
        return json.dumps(results, ensure_ascii=False)

    except Exception as e:
        logger.error(f"âŒ [Tool] Knowledge base search failed: {e}", exc_info=True)
        return f"æœç´¢çŸ¥è¯†åº“æ—¶å‡ºé”™: {str(e)}"


# å·¥å…·åˆ—è¡¨
tools = [search_knowledge_base]


# =============================================================================
# è¾…åŠ©å‡½æ•°ï¼šå¼•ç”¨æå–
# =============================================================================


# extract_citations_from_messages moved to app.core.rag_utils


# =============================================================================
# Agent å›¾æž„å»º
# =============================================================================


def create_agent_graph(checkpointer=None, model: ChatOpenAI = None):
    """åˆ›å»º ReAct Agent å›¾

    Args:
        checkpointer: å¯é€‰çš„ Checkpointer å®žä¾‹
        model: é…ç½®å¥½çš„ LLM å®žä¾‹ (å¿…é¡»æ”¯æŒ bind_tools)

    Returns:
        ç¼–è¯‘åŽçš„ StateGraph
    """
    if model is None:
        raise ValueError("Model must be provided to create_agent_graph")

    # 1. ç»‘å®šå·¥å…·åˆ°æ¨¡åž‹
    model_with_tools = model.bind_tools(tools)

    # 2. å®šä¹‰èŠ‚ç‚¹
    async def agent_node(state: ChatGraphState) -> dict:
        """Agent å†³ç­–èŠ‚ç‚¹"""
        logger.debug("ðŸ¤– [Agent] Thinking...")
        messages = list(state["messages"])

        # æ³¨å…¥/æ›´æ–° System Prompt (åŒ…å«æ‘˜è¦)
        system_content = SYSTEM_PROMPT
        if state.get("summary"):
            system_content += f"\n\n#### ä¹‹å‰çš„å¯¹è¯æ‘˜è¦ ####\n{state['summary']}"

        # ç¡®ä¿ç¬¬ä¸€æ¡æ¶ˆæ¯å§‹ç»ˆæ˜¯åŒ…å«æœ€æ–°æ‘˜è¦çš„ SystemMessage
        if not messages or not isinstance(messages[0], SystemMessage):
            messages.insert(0, SystemMessage(content=system_content))
        else:
            messages[0] = SystemMessage(content=system_content)

        response = await model_with_tools.ainvoke(messages)
        return {"messages": [response]}

    async def summarize_conversation(state: ChatGraphState) -> dict:
        """å¯¹è¯æ‘˜è¦èŠ‚ç‚¹"""
        logger.info("ðŸ“ [Summarize] Summarizing conversation history...")
        messages = state["messages"]
        summary = state.get("summary", "")

        # æž„é€ æ‘˜è¦ prompt
        summarize_message = SUMMARIZE_PROMPT
        if summary:
            summarize_message += f"\n\n(çŽ°æœ‰æ‘˜è¦: {summary})"

        # åªå–é™¤äº† SystemMessage/RemoveMessage ä¹‹å¤–çš„æ¶ˆæ¯è¿›è¡Œæ‘˜è¦
        conversation_messages = [msg for msg in messages if is_meaningful_message(msg)]

        if not conversation_messages:
            return {}

        # æ·»åŠ æ‘˜è¦æŒ‡ä»¤ (HumanMessage)
        prompt_messages = conversation_messages + [HumanMessage(content=summarize_message)]

        # è°ƒç”¨æ¨¡åž‹ç”Ÿæˆæ‘˜è¦
        response = await model.ainvoke(prompt_messages)
        new_summary = str(response.content)
        logger.info(f"ðŸ“ [Summarize] New summary: {new_summary[:100]}...")

        # åˆ é™¤æ—§æ¶ˆæ¯ï¼Œä¿ç•™æœ€è¿‘çš„ N æ¡äº¤äº’
        KEEP_LAST_N = 6
        if len(conversation_messages) > KEEP_LAST_N:
            # è®¡ç®—éœ€è¦åˆ é™¤çš„æ¶ˆæ¯
            messages_to_delete = conversation_messages[:-KEEP_LAST_N]
            delete_messages = [RemoveMessage(id=m.id) for m in messages_to_delete if m.id]
            logger.info(f"ðŸ—‘ï¸ [Summarize] Pruning {len(delete_messages)} old messages")
            return {"summary": new_summary, "messages": delete_messages}

        return {"summary": new_summary}

    # 3. æž„å»ºå›¾
    graph_builder = StateGraph(ChatGraphState)

    # å·¥å…·èŠ‚ç‚¹åŒ…è£…å™¨ï¼šé€’å¢žè¿­ä»£è®¡æ•° + æ£€æµ‹ç©ºç»“æžœ
    tool_node = ToolNode(tools)

    # è¿žç»­ç©ºç»“æžœç»ˆæ­¢é˜ˆå€¼ï¼ˆä»Žé…ç½®è¯»å–ï¼‰
    MAX_CONSECUTIVE_EMPTY = settings.AGENT_MAX_CONSECUTIVE_EMPTY
    SUMMARY_TRIGGER_COUNT = settings.AGENT_SUMMARY_TRIGGER_MSG_COUNT

    async def tools_wrapper_node(state: ChatGraphState) -> dict:
        """å·¥å…·èŠ‚ç‚¹åŒ…è£…å™¨ï¼Œæ‰§è¡Œå·¥å…·å¹¶è¿½è¸ªè¿­ä»£è®¡æ•°å’Œç©ºç»“æžœ"""
        current_count = state.get("iteration_count", 0)
        consecutive_empty = state.get("consecutive_empty_count", 0)

        # æ£€æŸ¥æ˜¯å¦è§¦åŠä¸­æ­¢é˜ˆå€¼
        if current_count >= MAX_ITERATIONS or consecutive_empty >= MAX_CONSECUTIVE_EMPTY:
            logger.warning(
                f"âš ï¸ [Graph] Force stopping tools. Iterations: {current_count}, Empty: {consecutive_empty}"
            )
            # ç”Ÿæˆä¸­æ­¢æç¤ºç»™ Agentï¼Œè¦æ±‚å…¶åœæ­¢æœç´¢å¹¶ç›´æŽ¥å›žç­”
            last_msg = state["messages"][-1]
            tool_messages = []
            if hasattr(last_msg, "tool_calls"):
                for tool_call in last_msg.tool_calls:
                    tool_messages.append(
                        ToolMessage(
                            tool_call_id=tool_call["id"],
                            content=FORCE_STOP_PROMPT,
                        )
                    )

            return {
                "messages": tool_messages,
                "iteration_count": current_count + 1,
                "consecutive_empty_count": consecutive_empty,
            }

        # æ­£å¸¸æ‰§è¡Œå·¥å…·
        result = await tool_node.ainvoke(state)

        # é€’å¢žè¿­ä»£è®¡æ•°
        result["iteration_count"] = current_count + 1

        # æ£€æµ‹å·¥å…·è¿”å›žæ˜¯å¦ä¸ºç©ºç»“æžœ
        is_empty_result = False
        if result.get("messages"):
            last_tool_msg = result["messages"][-1]
            if last_tool_msg:
                content = getattr(last_tool_msg, "content", "")
                if content == NO_RESULTS_MESSAGE or "æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£" in content or content == "[]":
                    is_empty_result = True

        if is_empty_result:
            result["consecutive_empty_count"] = consecutive_empty + 1
            logger.debug(
                f"ðŸ”„ [Graph] Empty result, consecutive count: {result['consecutive_empty_count']}/{MAX_CONSECUTIVE_EMPTY}"
            )
        else:
            result["consecutive_empty_count"] = 0

        logger.debug(f"ðŸ”„ [Graph] Iteration count: {result['iteration_count']}/{MAX_ITERATIONS}")
        return result

    # æ¡ä»¶è·¯ç”±å‡½æ•°ï¼šæ£€æŸ¥è¿­ä»£æ¬¡æ•°é™åˆ¶ + è¿žç»­ç©ºç»“æžœ
    def route_after_agent(state: ChatGraphState) -> Literal["tools", "should_summarize"]:
        """Agent åŽçš„è·¯ç”±å†³ç­–"""
        messages = state["messages"]
        last_message = messages[-1] if messages else None

        # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
        if last_message and hasattr(last_message, "tool_calls") and last_message.tool_calls:
            # å³ä½¿å·²ç»è¶…å‡ºé™åˆ¶ï¼Œä¹Ÿæœ€åŽä¸€æ¬¡è·¯ç”±åˆ° tools èŠ‚ç‚¹ï¼Œç”± tools_wrapper_node æ³¨å…¥â€œåœæ­¢â€æŒ‡ä»¤
            # è¿™æ ·å¯ä»¥ç¡®ä¿ Agent æ”¶åˆ°ä¸€ä¸ª ToolMessage å“åº”ï¼Œä»Žè€Œèƒ½å¤Ÿç”Ÿæˆæœ€ç»ˆçš„æ–‡æœ¬å›žå¤ã€‚
            return "tools"

        # å¦‚æžœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¯´æ˜Ž Agent å·²ç»ç”Ÿæˆäº†æ–‡æœ¬å›žå¤ï¼Œèµ°å‘æ‘˜è¦/ç»“æŸ
        return "should_summarize"

    async def check_summary_node(state: ChatGraphState) -> dict:
        """æ£€æŸ¥æ‘˜è¦èŠ‚ç‚¹çš„å ä½ç¬¦ï¼ˆPass-through nodeï¼‰"""
        # è¯¥èŠ‚ç‚¹ä¸ä¿®æ”¹çŠ¶æ€ï¼Œä»…ä½œä¸ºæ¡ä»¶è·¯ç”±çš„ä¸­è½¬
        return {}

    def should_summarize(state: ChatGraphState) -> Literal["summarize_conversation", "__end__"]:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦æ‘˜è¦"""
        messages = state["messages"]

        # ç®€å•ç­–ç•¥ï¼šéž System æ¶ˆæ¯æ€»æ•°è¶…è¿‡é˜ˆå€¼åˆ™è§¦å‘æ‘˜è¦
        non_system_msgs = [m for m in messages if not isinstance(m, SystemMessage)]

        # å®žé™…ç”Ÿäº§ä¸­å¯ä»¥è®¡ç®— Token æ•°
        if len(non_system_msgs) > SUMMARY_TRIGGER_COUNT:
            logger.info(
                f"ðŸ“Š [Graph] Message count {len(non_system_msgs)} > {SUMMARY_TRIGGER_COUNT}, triggering summarization"
            )
            return "summarize_conversation"

        return "__end__"

    graph_builder.add_node("agent", agent_node)
    graph_builder.add_node("tools", tools_wrapper_node)
    graph_builder.add_node("summarize_conversation", summarize_conversation)
    graph_builder.add_node("check_summary_node", check_summary_node)

    # 4. å®šä¹‰è¾¹
    graph_builder.add_edge(START, "agent")

    # æ¡ä»¶è¾¹: Agent -> (Tools | Check Summary)
    graph_builder.add_conditional_edges(
        "agent", route_after_agent, {"tools": "tools", "should_summarize": "check_summary_node"}
    )

    # å¾ªçŽ¯è¾¹: Tools -> Agent
    graph_builder.add_edge("tools", "agent")

    # æ¡ä»¶è¾¹: Check Summary -> (Summarize | End)
    graph_builder.add_conditional_edges(
        "check_summary_node",
        should_summarize,
        {"summarize_conversation": "summarize_conversation", "__end__": END},
    )

    # æ‘˜è¦ç»“æŸåŽ -> End
    graph_builder.add_edge("summarize_conversation", END)

    return graph_builder.compile(checkpointer=checkpointer)
