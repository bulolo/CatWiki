"""
æ–‡æ¡£ç®¡ç† API ç«¯ç‚¹
"""
import logging
import time

from fastapi import APIRouter, BackgroundTasks, Depends, Query, status
from sqlalchemy.ext.asyncio import AsyncSession

from app.core.deps import get_current_active_user
from app.core.exceptions import BadRequestException, NotFoundException
from app.core.utils import Paginator, build_collection_map, enrich_document_dict, get_vector_id
from app.crud import crud_collection, crud_document, crud_site
from app.db.database import AsyncSessionLocal, get_db
from app.models.document import Document as DocumentModel
from app.models.document import VectorStatus
from app.models.user import User
from app.schemas import ApiResponse, PaginatedResponse
from app.schemas.document import (
    Document,
    DocumentCreate,
    DocumentUpdate,
    VectorizeRequest,
    VectorizeResponse,
    VectorRetrieveRequest,
    VectorRetrieveResponse,
    VectorRetrieveResult,
)

router = APIRouter()
logger = logging.getLogger(__name__)


# ============ è¾…åŠ©å‡½æ•° ============

def can_vectorize(document: DocumentModel) -> bool:
    """æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å¯ä»¥å‘é‡åŒ–"""
    return document.vector_status in (
        VectorStatus.NONE,
        VectorStatus.FAILED,
        VectorStatus.COMPLETED,
        None
    )


# ============ å‘é‡åŒ–åå°ä»»åŠ¡ ============

async def process_vectorization_task(document_id: int):
    """
    å¤„ç†æ–‡æ¡£å‘é‡åŒ–ä»»åŠ¡ï¼ˆå¼‚æ­¥åå°ä»»åŠ¡ï¼‰
    æµç¨‹ï¼špending -> processing -> [add to vector store] -> completed
    """
    import time
    task_start_time = time.time()
    logger.info(f"ğŸ”„ [Task] å¼€å§‹å¤„ç†å‘é‡åŒ–ä»»åŠ¡ | DocID: {document_id}")

    # åˆ›å»ºæ–°çš„æ•°æ®åº“ä¼šè¯
    async with AsyncSessionLocal() as db:
        try:
            # æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å­˜åœ¨ä¸”çŠ¶æ€ä¸º pending
            document = await crud_document.get(db, id=document_id)
            if not document:
                logger.warning(f"âš ï¸ æ–‡æ¡£ {document_id} ä¸å­˜åœ¨ï¼Œè·³è¿‡å‘é‡åŒ–")
                return

            if document.vector_status != VectorStatus.PENDING:
                logger.warning(f"âš ï¸ æ–‡æ¡£ {document_id} çŠ¶æ€ä¸ä¸º pending ({document.vector_status})ï¼Œè·³è¿‡å‘é‡åŒ–")
                return

            # æ›´æ–°ä¸º processing çŠ¶æ€
            await crud_document.update_vector_status(db, document_id=document_id, status=VectorStatus.PROCESSING)

            # è·å–æ–‡æ¡£å†…å®¹
            if not document.content:
                logger.warning(f"âš ï¸ æ–‡æ¡£ {document_id} å†…å®¹ä¸ºç©ºï¼Œæ— æ³•å‘é‡åŒ–")
                await crud_document.update_vector_status(db, document_id=document_id, status=VectorStatus.FAILED, error="æ–‡æ¡£å†…å®¹ä¸ºç©º")
                return

            # å‡†å¤‡ LangChain æ–‡æ¡£å¯¹è±¡

            from app.core.vector_store import VectorStoreManager

            # åˆå§‹åŒ–å‘é‡å­˜å‚¨ç®¡ç†å™¨
            # åˆå§‹åŒ–å‘é‡å­˜å‚¨ç®¡ç†å™¨
            vector_store = await VectorStoreManager.get_instance()

            # 1. å‡†å¤‡å…ƒæ•°æ®
            base_metadata = {
                "source": "document",
                "id": str(document.id),
                "title": document.title,
                "author": document.author,
                "site_id": document.site_id,
                "collection_id": document.collection_id,
            }

            # 2. æ–‡æœ¬åˆ‡ç‰‡
            from langchain_text_splitters import RecursiveCharacterTextSplitter

            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=1000,
                chunk_overlap=200,
                length_function=len,
            )

            # ä½¿ç”¨ create_documents è‡ªåŠ¨å¤„ç†åˆ‡ç‰‡
            chunks = text_splitter.create_documents(
                texts=[document.content],
                metadatas=[base_metadata]
            )

            logger.info(f"ğŸ“„ æ–‡æ¡£ {document_id} å·²åˆ‡åˆ†ä¸º {len(chunks)} ä¸ªç‰‡æ®µ")

            # 3. ç”Ÿæˆç¡®å®šæ€§ ID (uuid5)
            # å¼•å…¥ uuid å’Œ NAMESPACE
            import uuid

            from app.core.vector_store import VectorStoreManager
            from app.core.utils import NAMESPACE_CATWIKI

            chunk_ids = []
            for i, chunk in enumerate(chunks):
                # ä¸ºæ¯ä¸ª chunk ç”Ÿæˆå”¯ä¸€çš„ç¡®å®šæ€§ ID: doc_{id}_chunk_{i}
                chunk_id_str = f"{document.id}_chunk_{i}"
                chunk_uuid = str(uuid.uuid5(NAMESPACE_CATWIKI, chunk_id_str))
                chunk_ids.append(chunk_uuid)

                # ç¡®ä¿ metadata ä¸­åŒ…å« id (è™½ç„¶ base_metadata å·²åŒ…å«ï¼Œä½† double check)
                chunk.metadata["id"] = str(document.id)
                chunk.metadata["chunk_index"] = i

            # 4. æ¸…ç†æ—§æ•°æ® (ä½¿ç”¨ delete_by_metadata)
            # å¿…é¡»åˆ é™¤è¯¥æ–‡æ¡£ ID å…³è”çš„æ‰€æœ‰å‘é‡ï¼Œå› ä¸ºåˆ‡ç‰‡æ•°é‡å¯èƒ½å˜åŒ–
            await vector_store.delete_by_metadata(key="id", value=str(document.id))

            # 5. æ·»åŠ æ–°å‘é‡
            if chunks:
                await vector_store.add_documents(documents=chunks, ids=chunk_ids)

            # æ›´æ–°ä¸º completed çŠ¶æ€
            await crud_document.update_vector_status(db, document_id=document_id, status=VectorStatus.COMPLETED)

            total_elapsed = time.time() - task_start_time
            logger.info(f"âœ¨ [Task] æ–‡æ¡£å‘é‡åŒ–å®Œæˆ! | ID: {document.id} | Chunks: {len(chunks)} | æ€»è€—æ—¶: {total_elapsed:.3f}s")

        except Exception as e:
            logger.error(f"âŒ æ–‡æ¡£ {document_id} å‘é‡åŒ–å¤±è´¥: {e}", exc_info=True)
            try:
                await crud_document.update_vector_status(db, document_id=document_id, status=VectorStatus.FAILED, error=str(e))
            except Exception as update_err:
                logger.warning(f"æ›´æ–°æ–‡æ¡£ {document_id} å‘é‡åŒ–çŠ¶æ€å¤±è´¥: {update_err}")


@router.get("", response_model=ApiResponse[PaginatedResponse[Document]], operation_id="listAdminDocuments")
async def list_documents(
    page: int = 1,
    size: int = 10,
    site_id: int | None = Query(None, description="ç«™ç‚¹ID"),
    collection_id: int | None = Query(None, description="åˆé›†ID"),
    status: str | None = Query(None, description="çŠ¶æ€è¿‡æ»¤: published, draft"),
    vector_status: str | None = Query(None, description="å‘é‡åŒ–çŠ¶æ€è¿‡æ»¤: none, pending, processing, completed, failed"),
    keyword: str | None = Query(None, description="æœç´¢å…³é”®è¯"),
    order_by: str | None = Query(None, description="æ’åºå­—æ®µ: views, updated_at"),
    order_dir: str | None = Query("desc", description="æ’åºæ–¹å‘: asc, desc"),
    exclude_content: bool = Query(True, description="æ˜¯å¦æ’é™¤æ–‡æ¡£å†…å®¹ï¼ˆç”¨äºåˆ—è¡¨å±•ç¤ºï¼Œæå‡æ€§èƒ½ï¼‰"),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user),
) -> ApiResponse[PaginatedResponse[Document]]:
    """è·å–æ–‡æ¡£åˆ—è¡¨ï¼ˆåˆ†é¡µï¼‰"""

    paginator = Paginator(page=page, size=size, total=0)  # total ç¨åè®¾ç½®

    # ç»Ÿä¸€æŸ¥è¯¢é€»è¾‘
    if collection_id:
        # è·å–åˆé›†åŠå…¶æ‰€æœ‰å­åˆé›†çš„IDåˆ—è¡¨
        collection_ids = await crud_collection.get_descendant_ids(db, collection_id=collection_id)
    else:
        collection_ids = None

    documents = await crud_document.list(
        db,
        site_id=site_id,
        collection_ids=collection_ids,
        status=status,
        vector_status=vector_status,
        keyword=keyword,
        skip=paginator.skip,
        limit=paginator.size,
        order_by=order_by,
        order_dir=order_dir
    )
    paginator.total = await crud_document.count(
        db, 
        site_id=site_id, 
        collection_ids=collection_ids, 
        status=status, 
        vector_status=vector_status,
        keyword=keyword
    )

    # æ‰¹é‡åŠ è½½æ‰€æœ‰éœ€è¦çš„collectionä¿¡æ¯ï¼ˆä¼˜åŒ–N+1æŸ¥è¯¢ï¼‰
    collection_ids = list(set([doc.collection_id for doc in documents if doc.collection_id]))
    collection_map = await build_collection_map(db, crud_collection, collection_ids)

    # ä¸ºæ¯ä¸ªæ–‡æ¡£æ·»åŠ åˆé›†ä¿¡æ¯
    documents_with_collection = []
    for doc in documents:
        doc_dict = await enrich_document_dict(
            doc, db, crud_collection,
            collection_map=collection_map
        )
        # å¤„ç† exclude_content é€»è¾‘
        if exclude_content:
            doc_dict['content'] = None
        documents_with_collection.append(doc_dict)

    return ApiResponse.ok(
        data=PaginatedResponse(
            list=documents_with_collection,
            pagination=paginator.to_pagination_info(),
        ),
        msg="è·å–æˆåŠŸ"
    )


@router.get("/{document_id}", response_model=ApiResponse[Document], operation_id="getAdminDocument")
async def get_document(
    document_id: int,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user),
) -> ApiResponse[Document]:
    """è·å–æ–‡æ¡£è¯¦æƒ…ï¼ˆç®¡ç†åå°æŸ¥çœ‹ï¼Œä¸å¢åŠ æµè§ˆé‡ï¼‰"""
    document = await crud_document.get_with_related_site(db, id=document_id)

    if not document:
        raise NotFoundException(detail=f"æ–‡æ¡£ {document_id} ä¸å­˜åœ¨")

    # æ„å»ºæ–‡æ¡£å­—å…¸ï¼Œæ·»åŠ å…³è”çš„åˆé›†ä¿¡æ¯
    document_dict = await enrich_document_dict(document, db, crud_collection, include_site_name=True)

    return ApiResponse.ok(data=document_dict, msg="è·å–æˆåŠŸ")


@router.post("", response_model=ApiResponse[Document], status_code=status.HTTP_201_CREATED, operation_id="createAdminDocument")
async def create_document(
    document_in: DocumentCreate,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user),
) -> ApiResponse[Document]:
    """åˆ›å»ºæ–‡æ¡£"""
    # éªŒè¯ç«™ç‚¹å­˜åœ¨
    site = await crud_site.get(db, id=document_in.site_id)
    if not site:
        raise BadRequestException(detail=f"ç«™ç‚¹ {document_in.site_id} ä¸å­˜åœ¨")

    # åˆ›å»ºæ–‡æ¡£ï¼ˆCRUD å±‚ä¼šè‡ªåŠ¨è®¡ç®—é˜…è¯»æ—¶é—´ï¼‰
    document = await crud_document.create(db, obj_in=document_in)

    # æ›´æ–°ç«™ç‚¹æ–‡ç« è®¡æ•°
    await crud_site.increment_article_count(db, site_id=document_in.site_id)

    # æ„å»ºæ–‡æ¡£å­—å…¸ï¼Œæ·»åŠ å…³è”çš„åˆé›†ä¿¡æ¯
    document_dict = await enrich_document_dict(document, db, crud_collection)

    return ApiResponse.ok(data=document_dict, msg="åˆ›å»ºæˆåŠŸ")


@router.put("/{document_id}", response_model=ApiResponse[Document], operation_id="updateAdminDocument")
async def update_document(
    document_id: int,
    document_in: DocumentUpdate,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user),
) -> ApiResponse[Document]:
    """æ›´æ–°æ–‡æ¡£"""
    document = await crud_document.get(db, id=document_id)
    if not document:
        raise NotFoundException(detail=f"æ–‡æ¡£ {document_id} ä¸å­˜åœ¨")

    # æ›´æ–°æ–‡æ¡£ï¼ˆCRUD å±‚ä¼šè‡ªåŠ¨è®¡ç®—é˜…è¯»æ—¶é—´ï¼‰
    document = await crud_document.update(db, db_obj=document, obj_in=document_in)

    # æ„å»ºæ–‡æ¡£å­—å…¸ï¼Œæ·»åŠ å…³è”çš„åˆé›†ä¿¡æ¯
    document_dict = await enrich_document_dict(document, db, crud_collection)

    return ApiResponse.ok(data=document_dict, msg="æ›´æ–°æˆåŠŸ")


@router.delete("/{document_id}", response_model=ApiResponse[None], operation_id="deleteAdminDocument")
async def delete_document(
    document_id: int,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user),
) -> ApiResponse[None]:
    """åˆ é™¤æ–‡æ¡£"""
    document = await crud_document.get(db, id=document_id)
    if not document:
        raise NotFoundException(detail=f"æ–‡æ¡£ {document_id} ä¸å­˜åœ¨")

    site_id = document.site_id

    # å°è¯•åˆ é™¤å‘é‡æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
    try:
        from app.core.vector_store import VectorStoreManager
        vector_store = await VectorStoreManager.get_instance()
        await vector_store.delete_by_metadata(key="document_id", value=str(document_id))
    except Exception as e:
        logger.warning(f"åˆ é™¤æ–‡æ¡£å‘é‡å¤±è´¥: {e}")

    await crud_document.delete(db, id=document_id)

    # æ›´æ–°ç«™ç‚¹æ–‡ç« è®¡æ•°
    await crud_site.decrement_article_count(db, site_id=site_id)

    return ApiResponse.ok(msg="åˆ é™¤æˆåŠŸ")


# ============ å‘é‡åŒ–ç›¸å…³æ¥å£ ============

@router.post(":batchVectorize", response_model=ApiResponse[VectorizeResponse], operation_id="batchVectorizeAdminDocuments")
async def vectorize_documents(
    request: VectorizeRequest,
    background_tasks: BackgroundTasks,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user),
) -> ApiResponse[VectorizeResponse]:
    """æ‰¹é‡å‘é‡åŒ–æ–‡æ¡£ï¼ˆå°†æ–‡æ¡£çŠ¶æ€è®¾ç½®ä¸º pendingï¼Œå¹¶å¯åŠ¨å‘é‡åŒ–åå°ä»»åŠ¡ï¼‰"""
    # è¾“å…¥éªŒè¯
    if not request.document_ids:
        raise BadRequestException(detail="æ–‡æ¡£IDåˆ—è¡¨ä¸èƒ½ä¸ºç©º")

    # æ‰¹é‡è·å–æ–‡æ¡£ï¼ˆä¼˜åŒ–ï¼šé¿å… N+1 æŸ¥è¯¢ï¼‰
    documents = await crud_document.get_multi(db, ids=request.document_ids)
    document_map = {doc.id: doc for doc in documents}

    success_ids = []
    failed_count = 0

    for doc_id in request.document_ids:
        document = document_map.get(doc_id)
        if document and can_vectorize(document):
            success_ids.append(doc_id)
        else:
            failed_count += 1

    # æ‰¹é‡æ›´æ–°çŠ¶æ€ï¼ˆä¼˜åŒ–ï¼šä¸€æ¬¡æ‰¹é‡æ›´æ–°ä»£æ›¿å¤šæ¬¡å•ç‹¬æ›´æ–°ï¼‰
    if success_ids:
        await crud_document.batch_update_vector_status(
            db,
            document_ids=success_ids,
            status=VectorStatus.PENDING
        )

    # ä¸ºæ¯ä¸ªæˆåŠŸçš„æ–‡æ¡£å¯åŠ¨å¼‚æ­¥åå°ä»»åŠ¡
    for doc_id in success_ids:
        background_tasks.add_task(process_vectorization_task, doc_id)

    return ApiResponse.ok(
        data=VectorizeResponse(
            success_count=len(success_ids),
            failed_count=failed_count,
            document_ids=success_ids
        ),
        msg=f"å·²å°† {len(success_ids)} ä¸ªæ–‡æ¡£åŠ å…¥å­¦ä¹ é˜Ÿåˆ—"
    )


@router.post("/{document_id}:vectorize", response_model=ApiResponse[Document], operation_id="vectorizeAdminDocument")
async def vectorize_single_document(
    document_id: int,
    background_tasks: BackgroundTasks,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user),
) -> ApiResponse[Document]:
    """å‘é‡åŒ–å•ä¸ªæ–‡æ¡£ï¼ˆä¼šå¯åŠ¨å‘é‡åŒ–åå°ä»»åŠ¡ï¼‰"""
    document = await crud_document.get(db, id=document_id)
    if not document:
        raise NotFoundException(detail=f"æ–‡æ¡£ {document_id} ä¸å­˜åœ¨")

    # æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å¯ä»¥å‘é‡åŒ–
    if not can_vectorize(document):
        raise BadRequestException(detail=f"æ–‡æ¡£å½“å‰çŠ¶æ€ä¸º {document.vector_status}ï¼Œæ— æ³•é‡æ–°å­¦ä¹ ")

    # æ›´æ–°çŠ¶æ€ä¸º pending
    document = await crud_document.update_vector_status(db, document_id=document_id, status=VectorStatus.PENDING)

    # å¯åŠ¨å¼‚æ­¥åå°ä»»åŠ¡
    background_tasks.add_task(process_vectorization_task, document_id)

    # æ„å»ºæ–‡æ¡£å­—å…¸
    document_dict = await enrich_document_dict(document, db, crud_collection)

    return ApiResponse.ok(data=document_dict, msg="å·²åŠ å…¥å­¦ä¹ é˜Ÿåˆ—")


@router.post("/{document_id}:removeVector", response_model=ApiResponse[Document], operation_id="removeAdminDocumentVector")
async def remove_document_vector(
    document_id: int,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user),
) -> ApiResponse[Document]:
    """ç§»é™¤æ–‡æ¡£å‘é‡ï¼ˆä»å‘é‡åº“åˆ é™¤å¹¶é‡ç½®çŠ¶æ€ä¸º noneï¼‰"""
    document = await crud_document.get(db, id=document_id)
    if not document:
        raise NotFoundException(detail=f"æ–‡æ¡£ {document_id} ä¸å­˜åœ¨")

    # å°è¯•ä»å‘é‡åº“åˆ é™¤æ•°æ®
    try:
        from app.core.vector_store import VectorStoreManager
        vector_store = await VectorStoreManager.get_instance()
        # ä½¿ç”¨ delete_by_metadata ç¡®ä¿åˆ é™¤è¯¥æ–‡æ¡£å…³è”çš„æ‰€æœ‰ chunk
        await vector_store.delete_by_metadata(key="id", value=str(document_id))
    except Exception as e:
        logger.warning(f"åˆ é™¤å‘é‡æ•°æ®å¤±è´¥: {e}")

    # æ›´æ–°çŠ¶æ€ä¸º none
    document = await crud_document.update_vector_status(db, document_id=document_id, status=VectorStatus.NONE)

    document_dict = await enrich_document_dict(document, db, crud_collection)

    return ApiResponse.ok(data=document_dict, msg="å·²ç§»é™¤å‘é‡æ•°æ®")


@router.get("/{document_id}/chunks", response_model=ApiResponse[list[dict]], operation_id="getAdminDocumentChunks")
async def get_document_chunks(
    document_id: int,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user),
) -> ApiResponse[list[dict]]:
    """è·å–æ–‡æ¡£çš„å‘é‡åˆ‡ç‰‡ä¿¡æ¯"""
    logger.info(f"ğŸ” [Chunks] Requesting chunks for document_id: {document_id}")
    document = await crud_document.get(db, id=document_id)
    if not document:
        logger.warning(f"âš ï¸ [Chunks] Document {document_id} not found")
        raise NotFoundException(detail=f"æ–‡æ¡£ {document_id} ä¸å­˜åœ¨")

    chunks = []
    try:
        from app.core.vector_store import VectorStoreManager
        vector_store = await VectorStoreManager.get_instance()
        chunks = await vector_store.get_chunks_by_metadata(key="id", value=str(document_id))
        logger.info(f"âœ… [Chunks] Found {len(chunks)} chunks for document {document_id}")
    except Exception as e:
        logger.error(f"âŒ [Chunks] Failed to get chunks: {e}", exc_info=True)
        # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œè¿”å›ç©ºåˆ—è¡¨

    return ApiResponse.ok(data=chunks, msg="è·å–æˆåŠŸ")

@router.post("/retrieve", response_model=ApiResponse[VectorRetrieveResult], operation_id="retrieveDocuments")
async def retrieve_vectors(
    request: VectorRetrieveRequest,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user),
) -> ApiResponse[VectorRetrieveResult]:
    """
    è¯­ä¹‰æ£€ç´¢å‘é‡æ•°æ®åº“ (delegates to VectorService)
    """
    try:
        from app.services.vector_service import VectorService
        
        # è½¬æ¢è¿‡æ»¤å™¨æ ¼å¼ (Schema åº”è¯¥å…¼å®¹ï¼Œä½†ä¸ºäº†ä¿é™©èµ·è§ï¼Œæ˜ç¡®è¿™é‡Œæ˜¯ VectorRetrieveRequest.filter -> VectorRetrieveFilter)
        # å®é™…ä¸Š Pydantic æ¨¡å‹æ˜¯ä¸€è‡´çš„
        
        results = await VectorService.retrieve(
            query=request.query,
            k=request.k,
            threshold=request.threshold,
            filter=request.filter,
            enable_rerank=request.enable_rerank,
            rerank_k=request.rerank_k
        )

        return ApiResponse.ok(
            data=VectorRetrieveResult(list=results),
            msg="æ£€ç´¢æˆåŠŸ"
        )

    except Exception as e:
        logger.error(f"æ£€ç´¢å¤±è´¥: {e}", exc_info=True)
        return ApiResponse.ok(
            data=VectorRetrieveResult(list=[]), 
            msg=f"æ£€ç´¢å¤±è´¥: {str(e)}"
        )
